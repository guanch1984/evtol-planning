{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from statsmodels.tsa.api import SimpleExpSmoothing \n",
    "import sys\n",
    "sys.tracebacklimit = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workdir = os.getcwd()\n",
    "average_travel_file = \"\\data\\Average Travel time by departure time.xlsx\"\n",
    "path = os.path.join(workdir+average_travel_file)\n",
    "\n",
    "avg_commute = pd.read_excel(path,header = 4)\n",
    "avg_commute.fillna(0)\n",
    "\n",
    "def clean_locations(string):\n",
    "    return re.findall(\"(?<=--)(.*)(?= PUMA)\",string)[0]\n",
    "\n",
    "avg_commute['Selected Geographies'] = avg_commute['Selected Geographies'].apply(lambda x: clean_locations(x))\n",
    "\n",
    "drop_col = avg_commute.columns[1]\n",
    "\n",
    "avg_commute.drop([drop_col],axis=1,inplace=True)\n",
    "avg_commute.fillna(np.NaN,inplace=True)\n",
    "avg_commute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = []\n",
    "for city in avg_commute['Selected Geographies']:\n",
    "    if re.match(\"\\w\", city):\n",
    "        sublist = re.split('[^\\s|\\w]',city)\n",
    "        for item in sublist:\n",
    "            if item != None:\n",
    "                if 'Cities' in item:\n",
    "                    item = item.strip('Cities')\n",
    "                    splits.append(item)\n",
    "                if \"Region\" in item:\n",
    "                    item = item.strip('Region')\n",
    "                    splits.append(item)\n",
    "                else:\n",
    "                    splits.append(item)\n",
    "    else:\n",
    "        splits.append(city)    \n",
    "\n",
    "\n",
    "semi_cleaned = list(set(splits))\n",
    "semi_cleaned.remove('')\n",
    "semi_cleaned.remove('North')\n",
    "semi_cleaned.remove('Northeast')\n",
    "semi_cleaned.remove('East')\n",
    "semi_cleaned.remove('Southeast')\n",
    "semi_cleaned.remove('South')\n",
    "semi_cleaned.remove('Southwest')\n",
    "#semi_cleaned.remove('West')\n",
    "semi_cleaned.remove('Northwest')\n",
    "semi_cleaned.remove(\"Central\")\n",
    "\n",
    "cleaned = [x.strip() for x in semi_cleaned]\n",
    "\n",
    "df = pd.DataFrame(index = avg_commute.columns[1:])\n",
    "for city in cleaned:\n",
    "    for geo in avg_commute['Selected Geographies']:\n",
    "        if city in geo:\n",
    "            df[city] = avg_commute[avg_commute['Selected Geographies'] == geo].values[:,1:].T\n",
    "        \n",
    "commute_by_city = df.transpose()\n",
    "commute_by_city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_time(string):\n",
    "    temp = re.findall(\"[\\d]{1,2}:[\\d]{2}[\\s][\\w][.][\\w][.]\",string)[0]\n",
    "    time = temp.split(\" \")\n",
    "    time[1] = time[1].upper().replace(\".\",\"\")\n",
    "    stringy = \" \".join(time)\n",
    "    return stringy\n",
    "\n",
    "commute_by_city\n",
    "\n",
    "old_cols = list(commute_by_city.columns.values)\n",
    "new_cols = pd.Series(old_cols).apply(lambda x: clean_time(x))\n",
    "new_cols = pd.to_datetime(new_cols, format=\"%I:%M %p\").dt.strftime('%H:%M')\n",
    "commute_by_city.set_axis(new_cols,axis=1,inplace= True)\n",
    "\n",
    "avg_T = commute_by_city.transpose()\n",
    "avg_T.index = pd.to_datetime(avg_T.index)\n",
    "avg_T = avg_T.resample('10T').sum()\n",
    "avg_T.index = pd.to_datetime(avg_T.index).strftime('%H:%M')\n",
    "avg_T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morning = avg_T.loc[\"01:30\":\"12:00\"]\n",
    "morning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(morning.index,morning['Castaic'])\n",
    "fit1 = SimpleExpSmoothing(morning['Castaic'], initialization_method=\"heuristic\").fit(smoothing_level=0.3, optimized=False)\n",
    "plt.scatter(morning.index,fit1.fittedvalues)\n",
    "plt.ylabel('Average Commute Time')\n",
    "plt.xlabel('Time of Day')\n",
    "plt.plot()\n",
    "fit1.sse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_smoothing = pd.DataFrame(columns = morning.columns)\n",
    "for i in range(9):\n",
    "    smooth = 0.1 + i/10\n",
    "    fit = morning.apply(lambda x: SimpleExpSmoothing(x, initialization_method=\"heuristic\").fit(smoothing_level=smooth, optimized=False).sse)\n",
    "    best_smoothing = best_smoothing.append(fit, ignore_index=True)\n",
    "best_smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(best_smoothing.apply(lambda x: np.mean(x),axis=1))\n",
    "plt.title('Average SSE over entire dataset for each 0.1 increase in smoothing parameter')\n",
    "plt.xlabel('smoothing coefficient')\n",
    "plt.ylabel('SSE')\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(morning.index,morning['Malibu'])\n",
    "fit3 = SimpleExpSmoothing(morning['Malibu'], initialization_method=\"heuristic\").fit(smoothing_level=0.5, optimized=False)\n",
    "plt.scatter(morning.index,fit3.fittedvalues)\n",
    "plt.title('Smoothed commute times[0.4] - Malibu')\n",
    "plt.ylabel('Average Commute Time - Minutes')\n",
    "plt.xlabel('Time of day')\n",
    "plt.plot()\n",
    "fit3.sse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoothed_commutes  = morning.apply(lambda x: SimpleExpSmoothing(x, initialization_method=\"heuristic\").fit(smoothing_level=0.5, optimized=False).fittedvalues)\n",
    "smoothed_commutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopy\n",
    "from geopy.geocoders import GeoNames\n",
    "gn = GeoNames(username='matthew.rand')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commute_statistics = pd.DataFrame(index=smoothed_commutes.columns)\n",
    "commute_statistics['Average Commute'] = smoothed_commutes.apply(lambda x: np.mean(x))\n",
    "commute_statistics['Variation in Commute Time'] = smoothed_commutes.apply(lambda x: np.std(x))\n",
    "#commute_statistics['Centroid'] = commute_statistics.apply(lambda x: gn.geocode(\"{} CA USA\".format(x))[1][::-1]  )\n",
    "\n",
    "commute_statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lat_long(city_name):\n",
    "    locale = \"{} California USA\".format(city_name)\n",
    "    place = gn.geocode(locale)\n",
    "    if place != None:\n",
    "        return place[1][::-1]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "centroids = []\n",
    "for index in commute_statistics.index.to_list():\n",
    "    centroids.append( get_lat_long(index))\n",
    "\n",
    "commute_statistics['Centroids'] = centroids\n",
    "commute_statistics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('my-sql-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a2481bed0cc1be8e4a04f83dbf62c4d80d85c943871aa8cb2eed80da9f1c0359"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
